{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HumanForYou Employee Turnover Analysis\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "This notebook analyzes employee turnover at HumanForYou, a pharmaceutical company in India with approximately 4,000 employees experiencing a 15% annual turnover rate.\n",
        "\n",
        "**Objective**: Identify factors influencing employee turnover and develop predictive models to help reduce attrition.\n",
        "\n",
        "**Deliverables**:\n",
        "1. Data exploration and preprocessing\n",
        "2. Feature engineering\n",
        "3. Multiple ML model development and comparison\n",
        "4. Model interpretation and insights\n",
        "5. Actionable recommendations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Import custom modules\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "from data_loader import (\n",
        "    load_general_data, load_manager_survey, load_employee_survey,\n",
        "    load_working_hours_data, merge_all_data\n",
        ")\n",
        "from preprocessing import (\n",
        "    handle_missing_values, encode_categorical_variables,\n",
        "    create_features, prepare_features_for_modeling, scale_features\n",
        ")\n",
        "from model_evaluation import (\n",
        "    evaluate_model, plot_confusion_matrix, plot_roc_curve,\n",
        "    compare_models, print_classification_report\n",
        ")\n",
        "\n",
        "# Machine Learning libraries\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Model interpretation\n",
        "import shap\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading\n",
        "\n",
        "Load all available datasets:\n",
        "- General HR data\n",
        "- Manager survey data\n",
        "- Employee survey data\n",
        "- Working hours data (from ZIP file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load all datasets\n",
        "print(\"Loading datasets...\")\n",
        "general_df = load_general_data('../data/general_data.csv')\n",
        "manager_df = load_manager_survey('../data/manager_survey_data.csv')\n",
        "employee_df = load_employee_survey('../data/employee_survey_data.csv')\n",
        "\n",
        "# Load working hours data (try CSV files first, then ZIP)\n",
        "try:\n",
        "    in_time_df, out_time_df = load_working_hours_data(\n",
        "        zip_path='../data/in_out_time.zip',\n",
        "        in_time_path='../data/in_time.csv',\n",
        "        out_time_path='../data/out_time.csv'\n",
        "    )\n",
        "    if in_time_df is not None and out_time_df is not None:\n",
        "        has_working_hours = True\n",
        "        print(\"Working hours data loaded successfully!\")\n",
        "    else:\n",
        "        has_working_hours = False\n",
        "        print(\"Warning: Working hours data not available\")\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not load working hours data: {e}\")\n",
        "    has_working_hours = False\n",
        "    in_time_df, out_time_df = None, None\n",
        "\n",
        "print(\"\\nData loading complete!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Exploration\n",
        "\n",
        "### 2.1 Initial Data Inspection\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display basic information about each dataset\n",
        "print(\"=\"*60)\n",
        "print(\"GENERAL DATA\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Shape: {general_df.shape}\")\n",
        "print(f\"\\nColumns: {list(general_df.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "display(general_df.head())\n",
        "print(f\"\\nData types:\")\n",
        "print(general_df.dtypes)\n",
        "print(f\"\\nMissing values:\")\n",
        "print(general_df.isnull().sum()[general_df.isnull().sum() > 0])\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MANAGER SURVEY DATA\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Shape: {manager_df.shape}\")\n",
        "display(manager_df.head())\n",
        "print(f\"\\nMissing values:\")\n",
        "print(manager_df.isnull().sum()[manager_df.isnull().sum() > 0])\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EMPLOYEE SURVEY DATA\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Shape: {employee_df.shape}\")\n",
        "display(employee_df.head())\n",
        "print(f\"\\nMissing values:\")\n",
        "print(employee_df.isnull().sum()[employee_df.isnull().sum() > 0])\n",
        "print(f\"\\nNA values (string):\")\n",
        "for col in employee_df.columns:\n",
        "    if col != 'EmployeeID':\n",
        "        na_count = (employee_df[col] == 'NA').sum()\n",
        "        if na_count > 0:\n",
        "            print(f\"{col}: {na_count}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Target Variable Analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze target variable (Attrition)\n",
        "if 'Attrition' in general_df.columns:\n",
        "    print(\"Attrition Distribution:\")\n",
        "    print(general_df['Attrition'].value_counts())\n",
        "    print(f\"\\nAttrition Rate: {(general_df['Attrition'] == 'Yes').sum() / len(general_df) * 100:.2f}%\")\n",
        "    \n",
        "    # Visualize attrition distribution\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    \n",
        "    # Count plot\n",
        "    general_df['Attrition'].value_counts().plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'])\n",
        "    axes[0].set_title('Attrition Distribution')\n",
        "    axes[0].set_xlabel('Attrition')\n",
        "    axes[0].set_ylabel('Count')\n",
        "    axes[0].tick_params(axis='x', rotation=0)\n",
        "    \n",
        "    # Pie chart\n",
        "    general_df['Attrition'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%', \n",
        "                                                colors=['#2ecc71', '#e74c3c'])\n",
        "    axes[1].set_title('Attrition Proportion')\n",
        "    axes[1].set_ylabel('')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nNote: This is an imbalanced dataset, which we'll need to address during modeling.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Exploratory Data Analysis\n",
        "\n",
        "#### 2.3.1 Demographic Analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze demographic factors\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Age distribution\n",
        "if 'Age' in general_df.columns:\n",
        "    general_df.groupby('Attrition')['Age'].hist(alpha=0.7, bins=20, ax=axes[0,0], legend=True)\n",
        "    axes[0,0].set_title('Age Distribution by Attrition')\n",
        "    axes[0,0].set_xlabel('Age')\n",
        "    axes[0,0].set_ylabel('Frequency')\n",
        "    axes[0,0].legend(['No', 'Yes'])\n",
        "\n",
        "# Gender analysis\n",
        "if 'Gender' in general_df.columns:\n",
        "    gender_attrition = pd.crosstab(general_df['Gender'], general_df['Attrition'], normalize='index') * 100\n",
        "    gender_attrition.plot(kind='bar', ax=axes[0,1], color=['#2ecc71', '#e74c3c'])\n",
        "    axes[0,1].set_title('Attrition Rate by Gender')\n",
        "    axes[0,1].set_xlabel('Gender')\n",
        "    axes[0,1].set_ylabel('Percentage')\n",
        "    axes[0,1].legend(['No', 'Yes'])\n",
        "    axes[0,1].tick_params(axis='x', rotation=0)\n",
        "\n",
        "# Marital Status\n",
        "if 'MaritalStatus' in general_df.columns:\n",
        "    marital_attrition = pd.crosstab(general_df['MaritalStatus'], general_df['Attrition'], normalize='index') * 100\n",
        "    marital_attrition.plot(kind='bar', ax=axes[1,0], color=['#2ecc71', '#e74c3c'])\n",
        "    axes[1,0].set_title('Attrition Rate by Marital Status')\n",
        "    axes[1,0].set_xlabel('Marital Status')\n",
        "    axes[1,0].set_ylabel('Percentage')\n",
        "    axes[1,0].legend(['No', 'Yes'])\n",
        "    axes[1,0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Education Field\n",
        "if 'EducationField' in general_df.columns:\n",
        "    edu_attrition = pd.crosstab(general_df['EducationField'], general_df['Attrition'], normalize='index') * 100\n",
        "    edu_attrition.plot(kind='barh', ax=axes[1,1], color=['#2ecc71', '#e74c3c'])\n",
        "    axes[1,1].set_title('Attrition Rate by Education Field')\n",
        "    axes[1,1].set_xlabel('Percentage')\n",
        "    axes[1,1].legend(['No', 'Yes'])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.3.2 Job-Related Factors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze job-related factors\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Monthly Income\n",
        "if 'MonthlyIncome' in general_df.columns:\n",
        "    general_df.boxplot(column='MonthlyIncome', by='Attrition', ax=axes[0,0])\n",
        "    axes[0,0].set_title('Monthly Income by Attrition')\n",
        "    axes[0,0].set_xlabel('Attrition')\n",
        "    axes[0,0].set_ylabel('Monthly Income (Rupees)')\n",
        "    axes[0,0].set_xticklabels(['No', 'Yes'])\n",
        "\n",
        "# Job Level\n",
        "if 'JobLevel' in general_df.columns:\n",
        "    joblevel_attrition = pd.crosstab(general_df['JobLevel'], general_df['Attrition'], normalize='index') * 100\n",
        "    joblevel_attrition.plot(kind='bar', ax=axes[0,1], color=['#2ecc71', '#e74c3c'])\n",
        "    axes[0,1].set_title('Attrition Rate by Job Level')\n",
        "    axes[0,1].set_xlabel('Job Level')\n",
        "    axes[0,1].set_ylabel('Percentage')\n",
        "    axes[0,1].legend(['No', 'Yes'])\n",
        "\n",
        "# Years at Company\n",
        "if 'YearsAtCompany' in general_df.columns:\n",
        "    general_df.boxplot(column='YearsAtCompany', by='Attrition', ax=axes[1,0])\n",
        "    axes[1,0].set_title('Years at Company by Attrition')\n",
        "    axes[1,0].set_xlabel('Attrition')\n",
        "    axes[1,0].set_ylabel('Years at Company')\n",
        "    axes[1,0].set_xticklabels(['No', 'Yes'])\n",
        "\n",
        "# Job Role\n",
        "if 'JobRole' in general_df.columns:\n",
        "    jobrole_attrition = pd.crosstab(general_df['JobRole'], general_df['Attrition'], normalize='index') * 100\n",
        "    jobrole_attrition['Yes'].sort_values(ascending=True).plot(kind='barh', ax=axes[1,1], color='#e74c3c')\n",
        "    axes[1,1].set_title('Attrition Rate by Job Role')\n",
        "    axes[1,1].set_xlabel('Attrition Rate (%)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.3.3 Survey Data Analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge data for survey analysis\n",
        "merged_temp = general_df.merge(manager_df, on='EmployeeID', how='left')\n",
        "merged_temp = merged_temp.merge(employee_df, on='EmployeeID', how='left')\n",
        "\n",
        "# Analyze survey responses\n",
        "survey_cols = ['JobInvolvement', 'PerformanceRating', 'EnvironmentSatisfaction', \n",
        "               'JobSatisfaction', 'WorkLifeBalance']\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, col in enumerate(survey_cols):\n",
        "    if col in merged_temp.columns:\n",
        "        # Replace 'NA' with NaN for proper handling\n",
        "        merged_temp[col] = merged_temp[col].replace('NA', np.nan)\n",
        "        merged_temp[col] = pd.to_numeric(merged_temp[col], errors='coerce')\n",
        "        \n",
        "        # Create crosstab\n",
        "        survey_attrition = pd.crosstab(merged_temp[col], merged_temp['Attrition'], normalize='index') * 100\n",
        "        survey_attrition.plot(kind='bar', ax=axes[idx], color=['#2ecc71', '#e74c3c'])\n",
        "        axes[idx].set_title(f'Attrition Rate by {col}')\n",
        "        axes[idx].set_xlabel(col)\n",
        "        axes[idx].set_ylabel('Percentage')\n",
        "        axes[idx].legend(['No', 'Yes'])\n",
        "        axes[idx].tick_params(axis='x', rotation=0)\n",
        "\n",
        "# Remove extra subplot\n",
        "fig.delaxes(axes[5])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Preprocessing\n",
        "\n",
        "### 3.1 Merge All Data Sources\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge all datasets\n",
        "if has_working_hours:\n",
        "    df = merge_all_data(general_df, manager_df, employee_df, in_time_df, out_time_df)\n",
        "else:\n",
        "    df = merge_all_data(general_df, manager_df, employee_df)\n",
        "\n",
        "print(f\"Final merged dataset shape: {df.shape}\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "\n",
        "# Check for duplicates\n",
        "print(f\"\\nDuplicate EmployeeIDs: {df['EmployeeID'].duplicated().sum()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Handle Missing Values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display missing values before preprocessing\n",
        "print(\"Missing values before preprocessing:\")\n",
        "missing_before = df.isnull().sum()\n",
        "missing_before = missing_before[missing_before > 0]\n",
        "if len(missing_before) > 0:\n",
        "    print(missing_before)\n",
        "else:\n",
        "    print(\"No missing values found (except 'NA' strings in survey data)\")\n",
        "\n",
        "# Handle missing values\n",
        "df_clean = handle_missing_values(df, strategy='median')\n",
        "\n",
        "# Display missing values after preprocessing\n",
        "print(\"\\nMissing values after preprocessing:\")\n",
        "missing_after = df_clean.isnull().sum()\n",
        "missing_after = missing_after[missing_after > 0]\n",
        "if len(missing_after) > 0:\n",
        "    print(missing_after)\n",
        "else:\n",
        "    print(\"All missing values handled!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Feature Engineering\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create additional features\n",
        "df_features = create_features(df_clean)\n",
        "\n",
        "print(f\"Original features: {df_clean.shape[1]}\")\n",
        "print(f\"Features after engineering: {df_features.shape[1]}\")\n",
        "print(f\"New features added: {df_features.shape[1] - df_clean.shape[1]}\")\n",
        "\n",
        "# Display new features\n",
        "new_features = set(df_features.columns) - set(df_clean.columns)\n",
        "if new_features:\n",
        "    print(f\"\\nNew features created: {list(new_features)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Encode Categorical Variables\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encode categorical variables\n",
        "df_encoded, encoders = encode_categorical_variables(df_features, target_col='Attrition')\n",
        "\n",
        "print(\"Categorical variables encoded:\")\n",
        "for col, encoder in encoders.items():\n",
        "    if col != 'Attrition':\n",
        "        print(f\"  {col}: {len(encoder.classes_)} unique values\")\n",
        "\n",
        "# Check target variable encoding\n",
        "if 'Attrition' in encoders:\n",
        "    print(f\"\\nAttrition encoding: {dict(zip(encoders['Attrition'].classes_, range(len(encoders['Attrition'].classes_))))}\")\n",
        "\n",
        "print(f\"\\nFinal dataset shape: {df_encoded.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.5 Prepare Features for Modeling\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features and target\n",
        "X, y = prepare_features_for_modeling(df_encoded, target_col='Attrition')\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"\\nTarget distribution:\")\n",
        "print(y.value_counts())\n",
        "print(f\"\\nTarget distribution (%):\")\n",
        "print(y.value_counts(normalize=True) * 100)\n",
        "\n",
        "# Display feature names\n",
        "print(f\"\\nFeature names ({len(X.columns)} features):\")\n",
        "print(list(X.columns))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.6 Train-Test Split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "print(f\"\\nTraining set target distribution:\")\n",
        "print(y_train.value_counts(normalize=True) * 100)\n",
        "print(f\"\\nTest set target distribution:\")\n",
        "print(y_test.value_counts(normalize=True) * 100)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.7 Handle Class Imbalance\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply SMOTE to handle class imbalance\n",
        "print(\"Before SMOTE:\")\n",
        "print(f\"Class distribution: {pd.Series(y_train).value_counts().to_dict()}\")\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"\\nAfter SMOTE:\")\n",
        "print(f\"Class distribution: {pd.Series(y_train_balanced).value_counts().to_dict()}\")\n",
        "print(f\"Training set size: {X_train_balanced.shape[0]} samples\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.8 Feature Scaling\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale features (for algorithms that require it)\n",
        "X_train_scaled, X_test_scaled, scaler = scale_features(\n",
        "    pd.DataFrame(X_train_balanced, columns=X.columns),\n",
        "    pd.DataFrame(X_test, columns=X.columns)\n",
        ")\n",
        "\n",
        "print(\"Features scaled successfully!\")\n",
        "print(f\"Scaled training set shape: {X_train_scaled.shape}\")\n",
        "print(f\"Scaled test set shape: {X_test_scaled.shape}\")\n",
        "\n",
        "# Also keep unscaled versions for tree-based models\n",
        "X_train_unscaled = X_train_balanced\n",
        "X_test_unscaled = X_test.values\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Development\n",
        "\n",
        "We will train and compare multiple classification models:\n",
        "1. Logistic Regression\n",
        "2. Random Forest\n",
        "3. Gradient Boosting\n",
        "4. XGBoost\n",
        "5. LightGBM\n",
        "6. Support Vector Machine (SVM)\n",
        "7. K-Nearest Neighbors (KNN)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
        "    'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='logloss'),\n",
        "    'LightGBM': lgb.LGBMClassifier(random_state=42, verbose=-1),\n",
        "    'SVM': SVC(probability=True, random_state=42),\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
        "}\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "print(\"Training models...\")\n",
        "print(\"=\"*60)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train and evaluate each model\n",
        "trained_models = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    \n",
        "    # Use scaled data for linear models, unscaled for tree-based models\n",
        "    if name in ['Logistic Regression', 'SVM', 'KNN']:\n",
        "        X_train_model = X_train_scaled\n",
        "        X_test_model = X_test_scaled\n",
        "    else:\n",
        "        X_train_model = X_train_unscaled\n",
        "        X_test_model = X_test_unscaled\n",
        "    \n",
        "    # Train model\n",
        "    model.fit(X_train_model, y_train_balanced)\n",
        "    trained_models[name] = model\n",
        "    \n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test_model)\n",
        "    y_pred_proba = model.predict_proba(X_test_model)[:, 1]\n",
        "    \n",
        "    # Evaluate model\n",
        "    metrics = evaluate_model(y_test, y_pred, y_pred_proba, model_name=name)\n",
        "    results.append(metrics)\n",
        "    \n",
        "    print(f\"  Accuracy: {metrics['Accuracy']:.4f}\")\n",
        "    print(f\"  Precision: {metrics['Precision']:.4f}\")\n",
        "    print(f\"  Recall: {metrics['Recall']:.4f}\")\n",
        "    print(f\"  F1-Score: {metrics['F1-Score']:.4f}\")\n",
        "    print(f\"  ROC-AUC: {metrics['ROC-AUC']:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"All models trained!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Model Comparison\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create results dataframe\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values('ROC-AUC', ascending=False)\n",
        "\n",
        "print(\"Model Performance Comparison:\")\n",
        "print(\"=\"*60)\n",
        "display(results_df)\n",
        "\n",
        "# Visualize comparison\n",
        "fig = compare_models(results_df)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Detailed Evaluation of Best Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select best model based on ROC-AUC\n",
        "best_model_name = results_df.iloc[0]['Model']\n",
        "best_model = trained_models[best_model_name]\n",
        "\n",
        "print(f\"Best Model: {best_model_name}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get predictions from best model\n",
        "if best_model_name in ['Logistic Regression', 'SVM', 'KNN']:\n",
        "    X_test_model = X_test_scaled\n",
        "else:\n",
        "    X_test_model = X_test_unscaled\n",
        "\n",
        "y_pred_best = best_model.predict(X_test_model)\n",
        "y_pred_proba_best = best_model.predict_proba(X_test_model)[:, 1]\n",
        "\n",
        "# Detailed evaluation\n",
        "print_classification_report(y_test, y_pred_best, model_name=best_model_name)\n",
        "\n",
        "# Visualizations\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Confusion Matrix\n",
        "plot_confusion_matrix(y_test, y_pred_best, model_name=best_model_name, ax=axes[0])\n",
        "\n",
        "# ROC Curve\n",
        "plot_roc_curve(y_test, y_pred_proba_best, model_name=best_model_name, ax=axes[1])\n",
        "\n",
        "# Precision-Recall Curve\n",
        "from model_evaluation import plot_precision_recall_curve\n",
        "plot_precision_recall_curve(y_test, y_pred_proba_best, model_name=best_model_name, ax=axes[2])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Interpretation\n",
        "\n",
        "### 5.1 Feature Importance\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract feature importance from tree-based models\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Importance': best_model.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "    \n",
        "    # Plot top 20 features\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    top_features = feature_importance.head(20)\n",
        "    plt.barh(range(len(top_features)), top_features['Importance'])\n",
        "    plt.yticks(range(len(top_features)), top_features['Feature'])\n",
        "    plt.xlabel('Feature Importance')\n",
        "    plt.title(f'Top 20 Feature Importance - {best_model_name}')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"Top 10 Most Important Features:\")\n",
        "    print(feature_importance.head(10))\n",
        "elif hasattr(best_model, 'coef_'):\n",
        "    # For linear models, use coefficients\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Coefficient': best_model.coef_[0]\n",
        "    }).sort_values('Coefficient', key=abs, ascending=False)\n",
        "    \n",
        "    plt.figure(figsize=(12, 8))\n",
        "    top_features = feature_importance.head(20)\n",
        "    colors = ['red' if x < 0 else 'green' for x in top_features['Coefficient']]\n",
        "    plt.barh(range(len(top_features)), top_features['Coefficient'], color=colors)\n",
        "    plt.yticks(range(len(top_features)), top_features['Feature'])\n",
        "    plt.xlabel('Coefficient Value')\n",
        "    plt.title(f'Top 20 Feature Coefficients - {best_model_name}')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"Top 10 Most Important Features (by absolute coefficient):\")\n",
        "    print(feature_importance.head(10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 SHAP Values (if applicable)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate SHAP values for tree-based models\n",
        "if hasattr(best_model, 'feature_importances_') or isinstance(best_model, (xgb.XGBClassifier, lgb.LGBMClassifier)):\n",
        "    try:\n",
        "        # Use a sample for SHAP (it can be computationally expensive)\n",
        "        sample_size = min(100, X_test_model.shape[0])\n",
        "        X_sample = X_test_model[:sample_size]\n",
        "        \n",
        "        # Create SHAP explainer\n",
        "        explainer = shap.TreeExplainer(best_model)\n",
        "        shap_values = explainer.shap_values(X_sample)\n",
        "        \n",
        "        # Plot SHAP summary\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        shap.summary_plot(shap_values, X_sample, feature_names=X.columns, show=False, max_display=20)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        print(\"SHAP values calculated successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not calculate SHAP values: {e}\")\n",
        "        print(\"This is normal for some model types or if SHAP is not properly configured.\")\n",
        "else:\n",
        "    print(\"SHAP analysis is most effective for tree-based models.\")\n",
        "    print(\"For linear models, coefficient analysis is provided above.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Improvement\n",
        "\n",
        "### 6.1 Hyperparameter Tuning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameter tuning for the best model\n",
        "print(f\"Tuning hyperparameters for {best_model_name}...\")\n",
        "\n",
        "# Define parameter grids based on model type\n",
        "if best_model_name == 'Random Forest':\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [10, 20, None],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    }\n",
        "    base_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "    X_train_tune = X_train_unscaled\n",
        "    X_test_tune = X_test_unscaled\n",
        "    \n",
        "elif best_model_name == 'XGBoost':\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [3, 5, 7],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'subsample': [0.8, 1.0]\n",
        "    }\n",
        "    base_model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
        "    X_train_tune = X_train_unscaled\n",
        "    X_test_tune = X_test_unscaled\n",
        "    \n",
        "elif best_model_name == 'LightGBM':\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [3, 5, 7],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'num_leaves': [31, 50, 70]\n",
        "    }\n",
        "    base_model = lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
        "    X_train_tune = X_train_unscaled\n",
        "    X_test_tune = X_test_unscaled\n",
        "    \n",
        "elif best_model_name == 'Gradient Boosting':\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [3, 5, 7],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "    base_model = GradientBoostingClassifier(random_state=42)\n",
        "    X_train_tune = X_train_unscaled\n",
        "    X_test_tune = X_test_unscaled\n",
        "    \n",
        "else:\n",
        "    print(\"Hyperparameter tuning skipped for this model type.\")\n",
        "    param_grid = None\n",
        "\n",
        "if param_grid:\n",
        "    # Perform grid search with cross-validation\n",
        "    grid_search = GridSearchCV(\n",
        "        base_model, \n",
        "        param_grid, \n",
        "        cv=5, \n",
        "        scoring='roc_auc', \n",
        "        n_jobs=-1, \n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    grid_search.fit(X_train_tune, y_train_balanced)\n",
        "    \n",
        "    print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
        "    print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
        "    \n",
        "    # Evaluate tuned model\n",
        "    tuned_model = grid_search.best_estimator_\n",
        "    y_pred_tuned = tuned_model.predict(X_test_tune)\n",
        "    y_pred_proba_tuned = tuned_model.predict_proba(X_test_tune)[:, 1]\n",
        "    \n",
        "    metrics_tuned = evaluate_model(y_test, y_pred_tuned, y_pred_proba_tuned, \n",
        "                                   model_name=f\"{best_model_name} (Tuned)\")\n",
        "    \n",
        "    print(\"\\nTuned Model Performance:\")\n",
        "    print(f\"  Accuracy: {metrics_tuned['Accuracy']:.4f}\")\n",
        "    print(f\"  Precision: {metrics_tuned['Precision']:.4f}\")\n",
        "    print(f\"  Recall: {metrics_tuned['Recall']:.4f}\")\n",
        "    print(f\"  F1-Score: {metrics_tuned['F1-Score']:.4f}\")\n",
        "    print(f\"  ROC-AUC: {metrics_tuned['ROC-AUC']:.4f}\")\n",
        "    \n",
        "    # Compare with original\n",
        "    original_metrics = results_df[results_df['Model'] == best_model_name].iloc[0]\n",
        "    print(f\"\\nImprovement in ROC-AUC: {metrics_tuned['ROC-AUC'] - original_metrics['ROC-AUC']:.4f}\")\n",
        "    \n",
        "    # Update best model\n",
        "    best_model = tuned_model\n",
        "    best_model_name = f\"{best_model_name} (Tuned)\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract and summarize key findings\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Importance': best_model.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "    \n",
        "    print(\"KEY FACTORS INFLUENCING EMPLOYEE TURNOVER\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nTop 15 Factors (by importance):\")\n",
        "    print(feature_importance.head(15).to_string(index=False))\n",
        "    \n",
        "    # Categorize factors\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"FACTOR CATEGORIZATION\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Job-related\n",
        "    job_factors = [f for f in feature_importance.head(15)['Feature'] \n",
        "                   if any(x in f.lower() for x in ['job', 'role', 'level', 'department'])]\n",
        "    print(f\"\\nJob-Related Factors: {len(job_factors)}\")\n",
        "    for f in job_factors:\n",
        "        print(f\"  - {f}\")\n",
        "    \n",
        "    # Compensation\n",
        "    comp_factors = [f for f in feature_importance.head(15)['Feature'] \n",
        "                    if any(x in f.lower() for x in ['income', 'salary', 'stock', 'hike'])]\n",
        "    print(f\"\\nCompensation-Related Factors: {len(comp_factors)}\")\n",
        "    for f in comp_factors:\n",
        "        print(f\"  - {f}\")\n",
        "    \n",
        "    # Experience\n",
        "    exp_factors = [f for f in feature_importance.head(15)['Feature'] \n",
        "                   if any(x in f.lower() for x in ['year', 'experience', 'tenure', 'promotion'])]\n",
        "    print(f\"\\nExperience/Tenure-Related Factors: {len(exp_factors)}\")\n",
        "    for f in exp_factors:\n",
        "        print(f\"  - {f}\")\n",
        "    \n",
        "    # Satisfaction\n",
        "    sat_factors = [f for f in feature_importance.head(15)['Feature'] \n",
        "                   if any(x in f.lower() for x in ['satisfaction', 'involvement', 'balance', 'rating'])]\n",
        "    print(f\"\\nSatisfaction-Related Factors: {len(sat_factors)}\")\n",
        "    for f in sat_factors:\n",
        "        print(f\"  - {f}\")\n",
        "    \n",
        "    # Work-life\n",
        "    wlb_factors = [f for f in feature_importance.head(15)['Feature'] \n",
        "                   if any(x in f.lower() for x in ['travel', 'distance', 'overtime', 'hours', 'balance'])]\n",
        "    print(f\"\\nWork-Life Balance Factors: {len(wlb_factors)}\")\n",
        "    for f in wlb_factors:\n",
        "        print(f\"  - {f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 Statistical Analysis of Key Factors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze key factors statistically\n",
        "key_factors = ['MonthlyIncome', 'YearsAtCompany', 'JobSatisfaction', \n",
        "               'EnvironmentSatisfaction', 'WorkLifeBalance', 'JobLevel',\n",
        "               'YearsSinceLastPromotion', 'DistanceFromHome', 'OverTime']\n",
        "\n",
        "# Merge back with target for analysis\n",
        "analysis_df = df_encoded.copy()\n",
        "\n",
        "print(\"STATISTICAL ANALYSIS OF KEY FACTORS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for factor in key_factors:\n",
        "    if factor in analysis_df.columns:\n",
        "        print(f\"\\n{factor}:\")\n",
        "        print(\"-\" * 40)\n",
        "        \n",
        "        # Compare means between attrition groups\n",
        "        if analysis_df[factor].dtype in [np.int64, np.float64]:\n",
        "            no_attrition = analysis_df[analysis_df['Attrition'] == 0][factor]\n",
        "            yes_attrition = analysis_df[analysis_df['Attrition'] == 1][factor]\n",
        "            \n",
        "            print(f\"  No Attrition - Mean: {no_attrition.mean():.2f}, Median: {no_attrition.median():.2f}\")\n",
        "            print(f\"  Attrition - Mean: {yes_attrition.mean():.2f}, Median: {yes_attrition.median():.2f}\")\n",
        "            print(f\"  Difference: {yes_attrition.mean() - no_attrition.mean():.2f}\")\n",
        "        else:\n",
        "            # For categorical variables\n",
        "            crosstab = pd.crosstab(analysis_df[factor], analysis_df['Attrition'], normalize='index') * 100\n",
        "            print(f\"  Attrition rates by category:\")\n",
        "            print(crosstab[1].sort_values(ascending=False).head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Recommendations and Actionable Insights\n",
        "\n",
        "Based on our analysis, here are the key recommendations for HumanForYou:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.1 Priority Recommendations\n",
        "\n",
        "1. **Address Job Satisfaction Issues**\n",
        "   - Job satisfaction is a critical factor in employee retention\n",
        "   - Implement regular satisfaction surveys and act on feedback\n",
        "   - Create clear career progression paths\n",
        "\n",
        "2. **Improve Work-Life Balance**\n",
        "   - High work-life balance dissatisfaction correlates with turnover\n",
        "   - Consider flexible working arrangements\n",
        "   - Review workload distribution and overtime policies\n",
        "\n",
        "3. **Enhance Compensation and Benefits**\n",
        "   - Review salary structures, especially for high-risk roles\n",
        "   - Ensure competitive compensation packages\n",
        "   - Consider performance-based bonuses and stock options\n",
        "\n",
        "4. **Focus on Career Development**\n",
        "   - Employees with longer time since last promotion show higher turnover\n",
        "   - Implement regular promotion cycles\n",
        "   - Provide clear advancement opportunities\n",
        "\n",
        "5. **Reduce Travel Burden**\n",
        "   - Frequent business travel is associated with higher turnover\n",
        "   - Consider alternatives to frequent travel (video conferencing)\n",
        "   - Provide adequate compensation for travel\n",
        "\n",
        "6. **Improve Manager Relationships**\n",
        "   - Years with current manager impacts retention\n",
        "   - Provide manager training programs\n",
        "   - Ensure stable manager-employee relationships\n",
        "\n",
        "7. **Target High-Risk Employee Segments**\n",
        "   - Focus retention efforts on:\n",
        "     - Employees with 1-3 years tenure\n",
        "     - Lower job levels\n",
        "     - Specific job roles with high turnover rates\n",
        "     - Employees living far from office\n",
        "\n",
        "### 8.2 Implementation Strategy\n",
        "\n",
        "1. **Short-term (0-3 months)**\n",
        "   - Conduct detailed exit interviews\n",
        "   - Launch employee satisfaction survey\n",
        "   - Review compensation for high-risk roles\n",
        "\n",
        "2. **Medium-term (3-6 months)**\n",
        "   - Implement flexible work policies\n",
        "   - Establish clear promotion criteria and timelines\n",
        "   - Launch manager training programs\n",
        "\n",
        "3. **Long-term (6-12 months)**\n",
        "   - Develop comprehensive retention strategy\n",
        "   - Create career development programs\n",
        "   - Establish predictive monitoring system using the model\n",
        "\n",
        "### 8.3 Model Deployment\n",
        "\n",
        "The developed model can be used to:\n",
        "- Identify employees at high risk of leaving\n",
        "- Prioritize retention efforts\n",
        "- Monitor effectiveness of interventions\n",
        "- Conduct \"what-if\" analyses for policy changes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Conclusion\n",
        "\n",
        "This analysis has identified key factors influencing employee turnover at HumanForYou and developed a predictive model with strong performance. The model can help management:\n",
        "\n",
        "1. **Predict** which employees are at risk of leaving\n",
        "2. **Understand** the key drivers of turnover\n",
        "3. **Prioritize** retention efforts effectively\n",
        "4. **Evaluate** the impact of policy changes\n",
        "\n",
        "**Next Steps:**\n",
        "- Deploy the model for ongoing monitoring\n",
        "- Implement recommended interventions\n",
        "- Track model performance and update regularly\n",
        "- Conduct follow-up analysis to measure intervention effectiveness\n",
        "\n",
        "---\n",
        "\n",
        "**Model Performance Summary:**\n",
        "- Best Model: [Will be displayed after model training]\n",
        "- ROC-AUC: [Will be displayed after model training]\n",
        "- Key Strengths: [Will be displayed after model training]\n",
        "- Areas for Improvement: [Will be displayed after model training]\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
